import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt

df = sns.load_dataset('iris')
print(df)
print()
df.info()

'''
붓꽃 데이터
1936년 논문에서 처음 사용
영국의 통계학자가 통계적 분류 기법을 설명하기 위해 만든 예제 데이터
총 150개 샘플

sepal_length (꽃받침 길이, cm)
sepal_width (꽃받침 너비, cm)
petal_length (꽃잎 길이, cm)
petal_width (꽃잎 너비, cm)

Setosa (세토사) -> 작고 단순한 꽃, 다른 두종과 확실히 구분가능
Versicolor (버시컬러) -> 중간 크기, 특징이 섞여있음
Virginica (버지니카) -> 가장 크고 구분 까다로움

'''

# 특성 4개 중에 2개로만 그래프 그려보기
sns.scatterplot(data=df, x="petal_length", y="petal_width", hue="species")
plt.show()

# 데이터 준비

X = df.drop("species", axis=1) # 인풋데이터
y = df["species"] # 타겟데이터

print('\n========= X (인풋 데이터) =========== \n')
print(X)

# 훈련 / 테스트 데이터셋 분리 8:2

train_input, test_input, train_target, test_target = train_test_split(X, y,test_size=0.2,random_state=42)


print(train_input.shape)
print(test_input.shape)
print(train_target.shape)
print(test_target.shape)

print('\n ======== train_input ======= \n')
print(train_input)

print('\n===== 데이터 준비 완료 =====\n')

# 모델준비 (최근접 이웃 모델 k=3)

kn = KNeighborsClassifier(n_neighbors=3)
kn.fit(train_input, train_target)

print('\n ====== 모델 준비 완료 ======\n')

# 테스트셋 예측
pred_target = kn.predict(test_input)

print('\n예측값:', pred_target)
print('\n실제값:', test_target)

train_score = kn.score(train_input, train_target)
test_score = kn.score(test_input, test_target)

print('\n트레인 스코어:', train_score)
print('\n테스트 스코어:', test_score)

print('\n====== 모델 학습 완료 =====\n')

from sklearn.metrics import accuracy_score
print('\n정확도:', accuracy_score(test_target, pred_target))


'''
score(인풋, 실제타겟) ---- 분류인 경우
내부작동
prded_target = kn.predict(test_input)
accuracy = (pred_target == test_target).mean()
return accuracy

accuracy_score(실제타겟, 예측타겟)
accuracy = (pred_target == test_target).mean()
return accuracy

실제값과 예측값만 있으면 된다. accuracy_score 말고도
Precision, Recall, F1 값 등, 다른 지표에도 바로 적용 가능.

'''

